{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper L Text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('input-file.xlsx', sheetname='Sheet3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>year</th>\n",
       "      <th>All notes</th>\n",
       "      <th>empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT0000741053</td>\n",
       "      <td>5</td>\n",
       "      <td>A provision of TEUR 19,493.0 (previous year: T...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT0000741053</td>\n",
       "      <td>6</td>\n",
       "      <td>Waste disposal or land restoration requirement...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT0000741053</td>\n",
       "      <td>7</td>\n",
       "      <td>Waste disposal or land restoration requirement...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ISIN  year                                          All notes  \\\n",
       "0  AT0000741053     5  A provision of TEUR 19,493.0 (previous year: T...   \n",
       "1  AT0000741053     6  Waste disposal or land restoration requirement...   \n",
       "2  AT0000741053     7  Waste disposal or land restoration requirement...   \n",
       "\n",
       "   empty  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 993 entries, 0 to 992\n",
      "Data columns (total 4 columns):\n",
      "ISIN         993 non-null object\n",
      "year         993 non-null int64\n",
      "All notes    993 non-null object\n",
      "empty        0 non-null float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 31.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat(policy,note):\n",
    "    text = 'NA'\n",
    "    if(type(policy) == str):\n",
    "        text = policy\n",
    "        \n",
    "    if(type(note) == str):\n",
    "        \n",
    "        if(text != 'NA'):\n",
    "            text += '. ' + note\n",
    "        else:\n",
    "            text = note\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Text']= data.apply(lambda row: concat(row['All notes'], row['empty']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                   993\n",
       "unique                                                  974\n",
       "top        Provisions for environmental restoration, res...\n",
       "freq                                                      4\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Text.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 993 entries, 0 to 992\n",
      "Data columns (total 5 columns):\n",
      "ISIN         993 non-null object\n",
      "year         993 non-null int64\n",
      "All notes    993 non-null object\n",
      "empty        0 non-null float64\n",
      "Text         993 non-null object\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 38.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A provision of TEUR 19,493.0 (previous year: T...\n",
       "1    Waste disposal or land restoration requirement...\n",
       "2    Waste disposal or land restoration requirement...\n",
       "3    Waste disposal or land restoration requirement...\n",
       "4    Waste disposal or land restoration requirement...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A provision of TEUR 19,493.0 (previous year: TEUR 16,259.5) was made for environmental and hazardous waste risks.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(data.Text.head()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentenceTokenize(paragraph):\n",
    "    \n",
    "    l_s = nltk.sent_tokenize(paragraph.lower())\n",
    "    \n",
    "    d_s =  {}\n",
    "    for sent in l_s:\n",
    "        \n",
    "        if ('rate' in sent):\n",
    "            \n",
    "            count = sent.count('rate')\n",
    "            if(sent not in d_s):\n",
    "                d_s[sent] = count\n",
    "            else:\n",
    "                d_s[sent] += count\n",
    "\n",
    "    sent_count = 0\n",
    "    sent_string = ''\n",
    "    \n",
    "    for key in d_s:\n",
    "        \n",
    "        sent_count += d_s[key]\n",
    "        sent_string += key\n",
    "        \n",
    "    return d_s,sent_string,sent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['rate_d','rate_sentences','rate_count']] = data.Text.apply(lambda paragraph: pd.Series(sentenceTokenize(paragraph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    993.000000\n",
       "mean       2.604230\n",
       "std        4.465534\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        3.000000\n",
       "max       37.000000\n",
       "Name: rate_count, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rate_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(fragment):\n",
    "    \n",
    "    fragments = nltk.sent_tokenize(fragment)\n",
    "    tokens = fragments\n",
    "    #Removes punctuation, paranthesis etc.\n",
    "    #tokens = re.sub(r'[^\\w\\s]', ' ', tokens)\n",
    "    #Makes lower case\n",
    "    #tokens = tokens.lower()\n",
    "    #Makes each word into a token in the sentece\n",
    "    tokens = [word_tokenize(fragment) for fragment in fragments]\n",
    "    #Removes english stopwords\n",
    "    #tokens = list(set(tokens) - stop)\n",
    "    #Lemmatizes each word\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Tokens'] = data.Text.apply(lambda text: tokenize(str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[A, provision, of, TEUR, 19,493.0, (, previou...\n",
       "1    [[Waste, disposal, or, land, restoration, requ...\n",
       "2    [[Waste, disposal, or, land, restoration, requ...\n",
       "3    [[Waste, disposal, or, land, restoration, requ...\n",
       "4    [[Waste, disposal, or, land, restoration, requ...\n",
       "Name: Tokens, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A provision of TEUR 19,493.0 (previous year: T...\n",
       "1    Waste disposal or land restoration requirement...\n",
       "2    Waste disposal or land restoration requirement...\n",
       "3    Waste disposal or land restoration requirement...\n",
       "4    Waste disposal or land restoration requirement...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmPanda = pd.read_csv('LoughranMcDonald_MasterDictionary_2016.csv')\n",
    "sentCols = ['Negative', 'Positive', 'Uncertainty', 'Litigious', 'Constraining', 'Superfluous', 'Interesting', 'Modal']\n",
    "sentDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in sentCols:\n",
    "    sentDict[col] = set([x.lower() for x in lmPanda[lmPanda[col] != 0]['Word'].tolist()])\n",
    "all_lists = data.Tokens.tolist()\n",
    "listofTokens = [val for sublist in all_lists for val in sublist]\n",
    "listofTokens = [val for sublist in listofTokens for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Creates a table with the idf scores with each word\n",
    "def idf(fragments):\n",
    "    vectorizer = TfidfVectorizer(min_df=1)\n",
    "    X = vectorizer.fit_transform(fragments)\n",
    "    idf = vectorizer.idf_\n",
    "    idfDict = dict(zip(vectorizer.get_feature_names(), idf))\n",
    "    return  idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creats the table with the idf scores\n",
    "idfDict = idf(listofTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def LMsent(tokens):\n",
    "    #Rules\n",
    "    \n",
    "    tokens = [val for sublist in tokens for val in sublist]\n",
    "    \n",
    "    tokenslen = len(tokens)\n",
    "    removeIndexes = []\n",
    "    if 'effective' in set(tokens):\n",
    "        for index in range(tokenslen - 1):\n",
    "            if ( tokens[index] == 'effective') & (tokens[index + 1] in ('income', 'tax', 'rate') ):\n",
    "                removeIndexes.append(index)\n",
    "                print('rule 1 applied')\n",
    "    if 'efficiency' in set(tokens):\n",
    "        for index in range(tokenslen - 1):\n",
    "            if ( tokens[index] == 'efficiency' ) & ( tokens[index + 1] in ('ratio') ):\n",
    "                removeIndexes.append(index)\n",
    "                print('rule 2 applied')\n",
    "\n",
    "    #Removes the words by indexes\n",
    "    if not removeIndexes:\n",
    "        #print tokens\n",
    "        for index in removeIndexes:\n",
    "            tokens.pop(index)\n",
    "        #print tokens\n",
    "\n",
    "    returnDict = {}\n",
    "    for key in sentDict.keys():\n",
    "        returnDict[key] = 0.0\n",
    "\n",
    "    #Makes the tokens into a dict of counts\n",
    "    counts = Counter(tokens)\n",
    "\n",
    "    if len(counts) != 0:  # List of tokens might be empty\n",
    "        # The token might be in several sets\n",
    "        tokensCount = 0\n",
    "        for token in counts:\n",
    "            token = token.lower()\n",
    "            for key in sentDict.keys():\n",
    "                # The token might be in many sets\n",
    "                if token in sentDict[key]:\n",
    "                    try:\n",
    "                        #Fetches the already calculated idfscore\n",
    "                        idfScore = idfDict[token]\n",
    "                        #Calculates the tfidfScore\n",
    "                        tfidf = idfScore*counts[token]/len(counts)\n",
    "                        returnDict[key] += tfidf\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(token)\n",
    "    return returnDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns the results ordered\n",
    "def LMs(tokens):\n",
    "    sentDict = LMsent(tokens)\n",
    "    sentList = []\n",
    "    for key in sentCols:\n",
    "        sentList.append(sentDict[key])\n",
    "    return sentList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.562314729628, 0.0, 0.419383576649, 0.0, 0.0...\n",
       "1    [0.774004424554, 0.0, 0.0, 0.323948061017, 0.7...\n",
       "2    [0.741754240198, 0.0, 0.0, 0.310450225142, 0.7...\n",
       "3    [0.741754240198, 0.0, 0.0, 0.310450225142, 0.7...\n",
       "4    [0.741754240198, 0.0, 0.0, 0.310450225142, 0.7...\n",
       "Name: Tokens, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Tokens.head().apply(lambda note: LMs(note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentCol = [col  for col in sentCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule 1 applied\n",
      "rule 1 applied\n",
      "rule 1 applied\n",
      "rule 1 applied\n"
     ]
    }
   ],
   "source": [
    "data[sentCol] = data.Tokens.apply(lambda note_tokens: pd.Series(LMs(note_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Superfluous</th>\n",
       "      <th>Interesting</th>\n",
       "      <th>Modal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.562315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.774004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323948</td>\n",
       "      <td>0.764072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.732236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.741754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.732236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.741754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.732236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Negative  Positive  Uncertainty  Litigious  Constraining  Superfluous  \\\n",
       "0  0.562315       0.0     0.419384   0.000000      0.000000          0.0   \n",
       "1  0.774004       0.0     0.000000   0.323948      0.764072          0.0   \n",
       "2  0.741754       0.0     0.000000   0.310450      0.732236          0.0   \n",
       "3  0.741754       0.0     0.000000   0.310450      0.732236          0.0   \n",
       "4  0.741754       0.0     0.000000   0.310450      0.732236          0.0   \n",
       "\n",
       "   Interesting  Modal  \n",
       "0          0.0    0.0  \n",
       "1          0.0    0.0  \n",
       "2          0.0    0.0  \n",
       "3          0.0    0.0  \n",
       "4          0.0    0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[sentCol].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
